{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMPR Ex5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cohen-raz/image_processing/blob/main/IMPR_Ex5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_s74P6ES_w4"
      },
      "source": [
        "# 3 Dataset Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxKYwsmcycpu"
      },
      "source": [
        "def get_rand_window(im, crop_size, get_index=False):\n",
        "    \"\"\"\n",
        "    :return: if get index, then return random window indexing from given im\n",
        "            in given crop_size.\n",
        "            else return window\n",
        "    \"\"\"\n",
        "    max_row = im.shape[0] - crop_size[0]\n",
        "    max_col = im.shape[1] - crop_size[1]\n",
        "    rand_row = np.random.randint(0, max_row)\n",
        "    rand_col = np.random.randint(0, max_col)\n",
        "    if get_index:\n",
        "        return (rand_row, rand_row + crop_size[0]), (\n",
        "            rand_col, rand_col + crop_size[0])\n",
        "    return im[rand_row:rand_row + crop_size[0],\n",
        "           rand_col:rand_col + crop_size[0]]\n",
        "\n",
        "\n",
        "def load_dataset(filenames, batch_size, corruption_func, crop_size):\n",
        "    \"\"\"\n",
        "    A generator for generating pairs of image patches, corrupted and original\n",
        "    :param filenames: a list of filenames of clean images.\n",
        "    :param batch_size: The size of the batch of images for each iteration of Stochastic Gradient Descent.\n",
        "    :param corruption_func: A function receiving a numpy array representation of an image as a single argument, and returning a randomly corrupted version of the input image.\n",
        "    :param crop_size: A tuple (height, width) specifying the crop size of the patches to extract.\n",
        "    :return:outputs random tuples of the form (source_batch, target_batch), where each output variable is an array of shape(batch_size, height, width, 1).\n",
        "     target_batch is made of clean images and source_batch is their respective randomly corrupted version\n",
        "     according to corruption_func(im)\n",
        "    \"\"\"\n",
        "    files_dict = {}\n",
        "\n",
        "    while True:\n",
        "        rand_files = np.random.choice(filenames, size=batch_size, replace=True)\n",
        "        original_patch_lst = []\n",
        "        corrupted_patch_lst = []\n",
        "\n",
        "        for im_file in rand_files:\n",
        "            # check if image already cached\n",
        "            if im_file not in files_dict.keys():\n",
        "                files_dict[im_file] = read_image(im_file, 1)\n",
        "            current_im = files_dict[im_file]\n",
        "\n",
        "            # crop\n",
        "            large_regular_crop = get_rand_window(current_im, (\n",
        "                crop_size[0] * 3, crop_size[1] * 3))\n",
        "            large_corrupted_crop = corruption_func(large_regular_crop.copy())\n",
        "\n",
        "            row_index, col_index = get_rand_window(large_corrupted_crop,\n",
        "                                                   crop_size, get_index=True)\n",
        "            # set corruption to patch\n",
        "            corrupted_patch = large_corrupted_crop[row_index[0]:row_index[1],\n",
        "                              col_index[0]: col_index[1]]\n",
        "            regular_patch = large_regular_crop[row_index[0]:row_index[1],\n",
        "                            col_index[0]: col_index[1]]\n",
        "\n",
        "            corrupted_patch_lst.append(\n",
        "                (corrupted_patch - 0.5).reshape(corrupted_patch.shape[0],\n",
        "                                                corrupted_patch.shape[1], 1))\n",
        "            original_patch_lst.append(\n",
        "                (regular_patch - 0.5).reshape(regular_patch.shape[0],\n",
        "                                              regular_patch.shape[1], 1))\n",
        "\n",
        "        target_batch = np.stack(original_patch_lst, axis=0)\n",
        "        source_batch = np.stack(corrupted_patch_lst, axis=0)\n",
        "\n",
        "        yield source_batch, target_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIsQ1QCaTHFV"
      },
      "source": [
        "# 4 Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-E3uUt-XeX"
      },
      "source": [
        "def resblock(input_tensor, num_channels):\n",
        "    \"\"\"\n",
        "    Takes as input a symbolic input tensor and the number of channels for each of its convolutional layers, and returns the symbolic output tensor of the resnet block.\n",
        "    The convolutional layers should use “same” border mode, so as to not decrease the spatial dimension of the output tensor.\n",
        "    :param input_tensor: input tensor\n",
        "    :param num_channels: number of channels\n",
        "    :return: symbolic output tensor of the resnet block\n",
        "    \"\"\"\n",
        "    C=Conv2D(num_channels,(3,3),padding='same')(input_tensor)\n",
        "    A=Activation('relu')(C)\n",
        "    O=Conv2D(num_channels,(3,3),padding='same')(A)\n",
        "    add=Add()([O,input_tensor])\n",
        "    return Activation('relu')(add)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acXKxnOW_J2F"
      },
      "source": [
        "def build_nn_model(height, width, num_channels, num_res_blocks):\n",
        "    \"\"\"\n",
        "    Create an untrained Keras model with input dimension the shape of (height, width, 1), and all convolutional layers (including residual\n",
        "    blocks) with number of output channels equal to num_channels, except the very last convolutional layer which should have a single output channel.\n",
        "    The number of residual blocks should be equal to num_res_blocks.\n",
        "    :param height: height\n",
        "    :param width: width\n",
        "    :param num_channels: number of channels\n",
        "    :param num_res_blocks: number of residual blocks\n",
        "    :return: an untrained Keras model.\n",
        "    \"\"\"\n",
        "    input=Input(shape=(height,width,1))\n",
        "    C=Conv2D(num_channels,(3,3),padding='same')(input)\n",
        "    A=Activation('relu')(C)\n",
        "    current_input=A\n",
        "    for i in range(num_res_blocks):\n",
        "      current_input=resblock(current_input,num_channels)\n",
        "\n",
        "    final_c=Conv2D(1,(3,3),padding='same')(current_input)\n",
        "    add=Add()([input,final_c])\n",
        "    return Model(inputs=input,outputs=add)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYZy2JFTSHI"
      },
      "source": [
        "# 5 Training Networks for Image Restoration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGjzET_KDcEp"
      },
      "source": [
        "def train_model(model, images, corruption_func, batch_size, steps_per_epoch, num_epochs, num_valid_samples):\n",
        "    \"\"\"\n",
        "    Divide the images into a training set and validation set, using an 80-20 split, and generate from each set a dataset with the given batch size\n",
        "    and corruption function. Eventually it will train the model.\n",
        "    :param model:  a general neural network model for image restoration.\n",
        "    :param images: a list of file paths pointing to image files. You should assume these paths are complete, and should append anything to them.\n",
        "    :param corruption_func: a corruption function.\n",
        "    :param batch_size: the size of the batch of examples for each iteration of SGD.\n",
        "    :param steps_per_epoch: the number of update steps in each epoch.\n",
        "    :param num_epochs: the number of epochs for which the optimization will run.\n",
        "    :param num_valid_samples: the number of samples in the validation set to test on after every epoch.\n",
        "    \"\"\"\n",
        "    # split data\n",
        "    im_train,im_validation=train_test_split(images,train_size=0.8)\n",
        "    #create generator for each dataset \n",
        "    crop_size=model.inputs[0].shape\n",
        "    crop_size=(crop_size[1],crop_size[2])\n",
        "\n",
        "    data_gen_train=load_dataset(im_train,batch_size,corruption_func,crop_size)\n",
        "    data_gen_validation=load_dataset(im_validation,batch_size,corruption_func,crop_size)\n",
        "\n",
        "    num_valid_samples=num_valid_samples//batch_size\n",
        "    model.compile(loss=\"mean_squared_error\",optimizer=Adam(beta_2=0.9))\n",
        "    model.fit_generator(data_gen_train,steps_per_epoch=steps_per_epoch,epochs=num_epochs,validation_data=data_gen_validation,validation_steps =num_valid_samples, use_multiprocessing=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHjL2E7_TZpT"
      },
      "source": [
        "# 6 Image Restoration of Complete Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I65AJMUKGMbo"
      },
      "source": [
        "def restore_image(corrupted_image, base_model):\n",
        "    \"\"\"\n",
        "    Restore full images of any size\n",
        "    :param corrupted_image: a grayscale image of shape (height, width) and with values in the [0, 1] range of type float64 that is affected\n",
        "    by a corruption generated from the same corruption function encountered during training (the image is not necessarily from the training set though).\n",
        "    :param base_model: a neural network trained to restore small patches. The input and output of the network are images with values in the [−0.5, 0.5] range.\n",
        "    :return: the restored image\n",
        "    \"\"\"\n",
        "    a = Input(shape=(corrupted_image.shape[0], corrupted_image.shape[1], 1))\n",
        "    output = base_model(a)\n",
        "    new_model = Model(inputs=a, outputs=output)\n",
        "    \n",
        "    adapted_im = corrupted_image - 0.5\n",
        "    adapted_im=adapted_im.reshape(-1,adapted_im.shape[0], adapted_im.shape[1],1)\n",
        "    fitted_im = new_model.predict(adapted_im)[0]\n",
        "    return np.clip(fitted_im+0.5, 0, 1).reshape(corrupted_image.shape).astype(np.float64)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEezLoKhTiX7"
      },
      "source": [
        "# 7 Application to Image Denoising and Deblurring\n",
        "## 7.1 Image Denoising\n",
        "### 7.1.1 Gaussian Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQM0ziYlHmbF"
      },
      "source": [
        "def add_gaussian_noise(image, min_sigma, max_sigma):\n",
        "    \"\"\"\n",
        "    Add random gaussian noise to an image\n",
        "    :param image: a grayscale image with values in the [0, 1] range of type float64.\n",
        "    :param min_sigma: a non-negative scalar value representing the minimal variance of the gaussian distribution.\n",
        "    :param max_sigma: a non-negative scalar value larger than or equal to min_sigma, representing the maximal variance of the gaussian distribution\n",
        "    :return: the corrupted image\n",
        "    \"\"\"\n",
        "    sigma = np.random.uniform(min_sigma, max_sigma)\n",
        "    mean = 0\n",
        "    noise = np.random.normal(mean, sigma, (image.shape[0], image.shape[1]))\n",
        "    noised_im = np.around(255 * (image + noise)) / 255\n",
        "    return np.clip(noised_im, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgOviGuNT7cz"
      },
      "source": [
        "#@markdown ### 7.1.2 Training a Denoising Mode\n",
        "\n",
        "denoise_num_res_blocks = 5 #@param {type:\"slider\", min:1, max:15, step:1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBWU29kizCK9"
      },
      "source": [
        "def denoising_corruption_func(im):\n",
        "    min_sigma = 0\n",
        "    max_sigma = 0.2\n",
        "    return add_gaussian_noise(im, min_sigma, max_sigma)\n",
        "\n",
        "def learn_denoising_model(denoise_num_res_blocks, quick_mode=False):\n",
        "    \"\"\"\n",
        "    Train a denoising model\n",
        "    :param denoise_num_res_blocks: number of residual blocks\n",
        "    :param quick_mode: is quick mode\n",
        "    :return: the trained model\n",
        "    \"\"\"\n",
        "    filenames = images_for_denoising()\n",
        "    height = 24\n",
        "    width = 24\n",
        "    num_channels = 48\n",
        "\n",
        "    if quick_mode:\n",
        "        batch_size = 10\n",
        "        steps_per_epoch = 3\n",
        "        num_epochs = 2\n",
        "        num_valid_samples = 30\n",
        "    else:\n",
        "        batch_size = 100\n",
        "        steps_per_epoch = 100\n",
        "        num_epochs = 10\n",
        "        num_valid_samples = 1000\n",
        "    model = build_nn_model(height, width, num_channels, denoise_num_res_blocks)\n",
        "    train_model(model, filenames, denoising_corruption_func, batch_size, steps_per_epoch,\n",
        "                num_epochs, num_valid_samples)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "genzLhl1UFyX"
      },
      "source": [
        "## 7.2 Image Deblurring\n",
        "### 7.2.1 Motion Blur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9sU77StlIUn"
      },
      "source": [
        "def add_motion_blur(image, kernel_size, angle):\n",
        "    \"\"\"\n",
        "    Simulate motion blur on the given image using a square kernel of size kernel_size where the line has the given angle in radians, measured relative to the positive horizontal axis.\n",
        "    :param image: a grayscale image with values in the [0, 1] range of type float64.\n",
        "    :param kernel_size:  an odd integer specifying the size of the kernel.\n",
        "    :param angle: an angle in radians in the range [0, π).\n",
        "    :return: blurred image\n",
        "    \"\"\"\n",
        "    kernel = motion_blur_kernel(kernel_size, angle)\n",
        "    return convolve(image, kernel)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVk9XqcMlQnI"
      },
      "source": [
        "def random_motion_blur(image, list_of_kernel_sizes):\n",
        "    \"\"\"\n",
        "    Simulate motion blur on the given image using a square kernel of size kernel_size where the line has the given angle in radians, measured relative to the positive horizontal axis.\n",
        "    :param image: a grayscale image with values in the [0, 1] range of type float64.\n",
        "    :param list_of_kernel_sizes: a list of odd integers.\n",
        "    :return: blurred image\n",
        "    \"\"\"\n",
        "    angel = np.random.uniform(0, np.pi)\n",
        "    kernel_size = list_of_kernel_sizes[int(\n",
        "        np.random.uniform(0, len(list_of_kernel_sizes)))]\n",
        "    corrupted = add_motion_blur(image, kernel_size, angel)\n",
        "    corrupted = np.around(255 * corrupted) / 255\n",
        "    return np.clip(corrupted, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBbYvynYUTFM"
      },
      "source": [
        "#@markdown ### 7.2.2 Training a Deblurring Model\n",
        "\n",
        "\n",
        "deblur_num_res_blocks = 5 #@param {type:\"slider\", min:1, max:15, step:1}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3MOKxPF9g6k"
      },
      "source": [
        "def deblurring_corruption_func(im):\n",
        "    return random_motion_blur(im, [7])\n",
        "\n",
        "def learn_deblurring_model(deblur_num_res_blocks, quick_mode=False):\n",
        "    \"\"\"\n",
        "    Train a deblurring model\n",
        "    :param deblur_num_res_blocks: number of residual blocks\n",
        "    :param quick_mode: is quick mode\n",
        "    :return: the trained model\n",
        "    \"\"\"\n",
        "    filenames = images_for_deblurring()\n",
        "    height = 16\n",
        "    width = 16\n",
        "    num_channels = 32\n",
        "\n",
        "    if quick_mode:\n",
        "        batch_size = 10\n",
        "        steps_per_epoch = 3\n",
        "        num_epochs = 2\n",
        "        num_valid_samples = 30\n",
        "    else:\n",
        "        batch_size = 100\n",
        "        steps_per_epoch = 100\n",
        "        num_epochs = 10\n",
        "        num_valid_samples = 1000\n",
        "    model = build_nn_model(height, width, num_channels, deblur_num_res_blocks)\n",
        "    train_model(model, filenames, deblurring_corruption_func, batch_size, steps_per_epoch,\n",
        "                num_epochs, num_valid_samples)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh_tT0e_9IIz"
      },
      "source": [
        "##7.3 Image Super-resolution\n",
        "### 7.3.1 Image Low-Resolution Corruption\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9enSTSke9hH6"
      },
      "source": [
        "def super_resolution_corruption(image):\n",
        "    \"\"\"\n",
        "    Perform the super resolution corruption \n",
        "    :param image: a grayscale image with values in the [0, 1] range of type float64.\n",
        "    :return: corrupted image\n",
        "    \"\"\"\n",
        "    zoom_factor_lst = [2, 3, 4]\n",
        "    zoom_factor = zoom_factor_lst[int(np.random.uniform(0, 3))]\n",
        "\n",
        "    reduced_im = zoom(image, 1 / zoom_factor)\n",
        "\n",
        "    w_correction = image.shape[0] / reduced_im.shape[0]\n",
        "    h_correction = image.shape[1] / reduced_im.shape[1]\n",
        "\n",
        "    return zoom(reduced_im, (w_correction, h_correction))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PnKb7iB-B1x"
      },
      "source": [
        "#@markdown ### 7.3.2 Training a Super Resolution Model\n",
        "\n",
        "\n",
        "super_resolution_num_res_blocks = 15 #@param {type:\"slider\", min:1, max:15, step:1}\n",
        "batch_size = 65 #@param {type:\"slider\", min:1, max:128, step:16}\n",
        "steps_per_epoch = 300 #@param {type:\"slider\", min:100, max:5000, step:100}\n",
        "num_epochs = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "patch_size = 16 #@param {type:\"slider\", min:8, max:32, step:2}\n",
        "num_channels = 32 #@param {type:\"slider\", min:16, max:64, step:2}\n",
        "num_valid_samples=1000\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZEOa7QV9kto"
      },
      "source": [
        "def learn_super_resolution_model(super_resolution_num_res_blocks, quick_mode=False):\n",
        "    \"\"\"\n",
        "    Train a super resolution model\n",
        "    :param super_resolution_num_res_blocks: number of residual blocks\n",
        "    :param quick_mode: is quick mode\n",
        "    :return: the trained model\n",
        "    \"\"\"\n",
        "    filenames = images_for_super_resolution()\n",
        "    height = 16\n",
        "    width = 16\n",
        "    num_channels=32\n",
        "\n",
        "    if quick_mode:\n",
        "        batch_size = 10\n",
        "        steps_per_epoch = 3\n",
        "        num_epochs = 2\n",
        "        num_valid_samples = 30\n",
        "    else:\n",
        "      batch_size = 65\n",
        "      steps_per_epoch = 300 \n",
        "      num_epochs = 10 \n",
        "      num_valid_samples = 1000\n",
        "\n",
        "\n",
        "    model = build_nn_model(height, width, num_channels, super_resolution_num_res_blocks)\n",
        "    train_model(model, filenames, super_resolution_corruption, batch_size, steps_per_epoch,\n",
        "                num_epochs, num_valid_samples)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}